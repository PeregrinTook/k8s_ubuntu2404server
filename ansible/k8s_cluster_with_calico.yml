---
- name: Kubernetes Cluster Setup with Calico and Containerd
  hosts: all
  become: yes
  vars:
    kube_version: "1.27.0"
    calico_version: "v3.26"
    containerd_version: "2.0.5"
    containerd_url: "https://github.com/containerd/containerd/releases/download/v{{ containerd_version }}/containerd-{{ containerd_version }}-linux-amd64.tar.gz"
    containerd_version_check: "2.0.5"


  tasks:
    # - name: Wait for cloud-init to complete
    #   ansible.builtin.command:
    #     cmd: cloud-init status --wait
    # # 0 update system
    # - name: Update and upgrade system packages
    #   ansible.builtin.apt:
    #     update_cache: yes
    #     upgrade: dist
    #     autoclean: yes
    #     autoremove: yes
    #     force: yes
    #   environment:
    #     DEBIAN_FRONTEND: noninteractive
    #   tags:
    #     - system_update
    # 1. Install Required Packages
    # - name: Install Required Packages
    #   apt:
    #     name:
    #       - apt-transport-https
    #       - curl
    #       - ca-certificates
    #       - gpg
    #     state: present
    #     update_cache: yes
    
    # # 2. Disable Swap
    # - name: Disable Swap
    #   ansible.builtin.shell: "swapoff -a && sed -i '/ swap / s/^/#/' /etc/fstab"

    # # 3. Update /etc/hosts
    # - name: Add multiple hosts to /etc/hosts
    #   ansible.builtin.blockinfile:
    #     path: /etc/hosts
    #     marker: "#<!-- {mark} ANSIBLE MANAGED BLOCK -->"
    #     block: |
    #       192.168.100.50 k8s-m
    #       192.168.100.51 k8s-w1
    #       192.168.100.52 k8s-w2
    #     state: present
    #     backup: yes

    # 4. Setup containerd modules
    - name: Ensure containerd.conf file exists
      ansible.builtin.file:
        path: /etc/modules-load.d/containerd.conf
        state: touch
        mode: '0644'

    - name: Add modules to containerd.conf
      ansible.builtin.lineinfile:
        path: /etc/modules-load.d/containerd.conf
        line: "{{ item }}"
        state: present
      loop:
        - "overlay"
        - "br_netfilter"

    # 5. Setup sysctl for Kubernetes
    - name: Ensure 99-kubernetes-cri.conf file exists
      ansible.builtin.file:
        path: /etc/sysctl.d/99-kubernetes-cri.conf
        state: touch
        mode: '0644'

    - name: Add sysctl settings for Kubernetes
      ansible.builtin.lineinfile:
        path: /etc/sysctl.d/99-kubernetes-cri.conf
        line: "{{ item }}"
        state: present
      loop:
        - "net.bridge.bridge-nf-call-iptables = 1"
        - "net.ipv4.ip_forward = 1"
        - "net.bridge.bridge-nf-call-ip6tables = 1"

    - name: Apply sysctl settings
      ansible.builtin.shell: sysctl --system

    # 6. Install Containerd
    
    - name: Download Containerd archive
      ansible.builtin.get_url:
        url: "{{ containerd_url }}"
        dest: "/tmp/containerd-{{ containerd_version }}-linux-amd64.tar.gz"
        mode: '0644'

    - name: Extract Containerd archive
      ansible.builtin.unarchive:
        src: "/tmp/containerd-{{ containerd_version }}-linux-amd64.tar.gz"
        dest: "/tmp/"
        remote_src: yes
    - name: Extract Containerd archive to /usr/local
      ansible.builtin.command:
        cmd: tar Cxzvf /usr/local /tmp/containerd-{{ containerd_version }}-linux-amd64.tar.gz
      become: yes
    - name: Get Containerd version
      ansible.builtin.command:
        cmd: containerd --version
      register: containerd_version_output


    - name: Print Containerd version
      debug:
        msg: "Containerd installed: {{ containerd_version_output.stdout }}"
    # 7. Install containerd.service
    - name: Download containerd systemd service file
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/containerd/containerd/main/containerd.service
        dest: /etc/systemd/system/containerd.service
        mode: '0644'

    - name: Reload systemd manager configuration
      ansible.builtin.shell: systemctl daemon-reload

    - name: Enable and start containerd service
      ansible.builtin.systemd:
        name: containerd
        enabled: true
        state: started
    # 8. Install runc
    
    - name: Ensure the directory exists
      ansible.builtin.file:
        path: /tmp/
        state: directory
        mode: '1777'

    - name: Download runc file
      ansible.builtin.get_url:
        url: https://github.com/opencontainers/runc/releases/download/v1.3.0/runc.amd64
        dest: /tmp/runc.amd64
        mode: '0644'

    - name: Install runc binary
      ansible.builtin.command:
        cmd: mv /tmp/runc.amd64 /usr/local/sbin/runc
      become: yes
    - name: Set correct permissions for runc binary
      ansible.builtin.file:
        path: /usr/local/sbin/runc
        mode: '0755'
        owner: root
        group: root
    # 8. CNI plugins

    - name: Download CNI plugins
      ansible.builtin.get_url:
        url: https://github.com/containernetworking/plugins/releases/download/v1.7.1/cni-plugins-linux-amd64-v1.7.1.tgz
        dest: /tmp/cni-plugins-linux-amd64-v1.7.1.tgz
        mode: '0644'

    - name: Create CNI bin directory
      ansible.builtin.file:
        path: /opt/cni/bin
        state: directory
        mode: '0755'

    - name: Extract CNI plugins
      ansible.builtin.unarchive:
        src: /tmp/cni-plugins-linux-amd64-v1.7.1.tgz
        dest: /opt/cni/bin
        remote_src: yes
    #9 containerd config
    - name: Create containerd config directory
      ansible.builtin.file:
        path: /etc/containerd
        state: directory
        mode: '0755'
        owner: root
        group: root

    - name: Generate containerd default configuration
      ansible.builtin.shell: |
        containerd config default | tee /etc/containerd/config.toml
      args:
        creates: /etc/containerd/config.toml
    - name: Ensure SystemdCgroup is enabled under the correct section
      ansible.builtin.blockinfile:
        path: /etc/containerd/config.toml
        marker: "# {mark} ANSIBLE MANAGED BLOCK"
        # [plugins.'io.containerd.cri.v1.runtime'.containerd.runtimes.runc.options]
        insertafter: |
          ^\s*\[plugins.'io.containerd.cri.v1.runtime'.containerd.runtimes.runc.options\]
        block: |
            # BEGIN ANSIBLE MANAGED BLOCK
                        SystemdCgroup = true
            # END ANSIBLE MANAGED BLOCK
    - name: Restart containerd
      ansible.builtin.systemd:
        name: containerd
        state: restarted
        enabled: true
    - name: Update APT package list
      ansible.builtin.apt:
        update_cache: yes
    # Download Kubernetes GPG key
    - name: Download Kubernetes GPG key
      ansible.builtin.shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      args:
        creates: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: Add Kubernetes APT repository
      ansible.builtin.lineinfile:
        path: /etc/apt/sources.list.d/kubernetes.list
        line: 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /'
        create: yes

    - name: Update APT package list again
      ansible.builtin.apt:
        update_cache: yes

    - name: Reboot server
      ansible.builtin.reboot:
        msg: "Rebooting the server"
        reboot_timeout: 600
# install k8s 
    - name: Install specific versions of Kubernetes components
      ansible.builtin.apt:
        name:
          - kubelet=1.31.3-1.1
          - kubeadm=1.31.3-1.1
          - kubectl=1.31.3-1.1
        state: present
        update_cache: yes

    - name: Mark Kubernetes packages on hold
      ansible.builtin.command:
        cmd: apt-mark hold kubelet kubeadm kubectl
    # Initialize Kubernetes control plane (only on master node)
- name: Initialize Kubernetes control plane (only on master node)
  hosts: master  # Это применится только к группе master
  become: yes
  tasks:
    - name: Run kubeadm init
      ansible.builtin.shell:
        cmd: "kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version 1.31.3 --node-name k8s-master"
      register: kubeadm_init_output
      failed_when: kubeadm_init_output.rc != 0  # Прекратить выполнение в случае ошибки

    - name: Set KUBECONFIG environment variable for root
      ansible.builtin.lineinfile:
        path: /root/.bashrc
        line: "export KUBECONFIG=/etc/kubernetes/admin.conf"
        create: yes
    - name: Create KUBECONFIG script in /etc/profile.d
      ansible.builtin.copy:
        dest: /etc/profile.d/kubeconfig.sh
        content: |
          #!/bin/bash
          export KUBECONFIG=/etc/kubernetes/admin.conf
        mode: 0755
    - name: Show kubeadm init output
      ansible.builtin.debug:
        msg: "{{ kubeadm_init_output.stdout }}"

    - name: Set up kubeconfig for kubectl access on master node
      ansible.builtin.shell:
        cmd: |
          mkdir -p /root/.kube
          cp -i /etc/kubernetes/admin.conf /root/.kube/config
          chown $(id -u):$(id -g) /root/.kube/config

    # Creating Calico 
    - name: Apply Calico Tigera Operator YAML file from URL
      ansible.builtin.shell: |
        kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/tigera-operator.yaml
      register: kubectl_create_output

    - name: Show output from kubectl create
      ansible.builtin.debug:
        msg: "{{ kubectl_create_output.stdout }}"

    - name: Download custom-resources.yaml file from URL
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/custom-resources.yaml
        dest: /tmp/custom-resources.yaml

    - name: Apply the custom-resources.yaml file
      ansible.builtin.shell: |
        kubectl create -f /tmp/custom-resources.yaml
      register: kubectl_create_output

    - name: Show output from kubectl create
      ansible.builtin.debug:
        msg: "{{ kubectl_create_output.stdout }}"
        # тут
    - name: Generate join command and save to file
      ansible.builtin.shell:
        cmd: kubeadm token create --print-join-command
      register: join_command
      changed_when: false
      run_once: true
      tags:
        - join

    - name: Save join command to file
      ansible.builtin.copy:
        content: "{{ join_command.stdout }}"
        dest: /root/kubeadm-join-command.sh
        mode: '0700'
      run_once: true
      tags:
        - join

- name: Join workers to cluster
  hosts: workers
  become: yes
  tasks:
    - name: Get join command from master
      ansible.builtin.slurp:
        src: /root/kubeadm-join-command.sh
      register: join_command_file
      delegate_to: "{{ groups['master'][0] }}"
      run_once: true
      tags:
        - join

    - name: Decode join command
      ansible.builtin.set_fact:
        join_command: "{{ join_command_file.content | b64decode }}"
      tags:
        - join

    - name: Execute join command
      ansible.builtin.shell: "{{ join_command }}"
      register: join_result
      ignore_errors: yes
      failed_when: >
        ('This node has joined the cluster' not in join_result.stdout) or
        (join_result.rc is defined and join_result.rc != 0)
      tags:
        - join

    - name: Verify node joined
      ansible.builtin.shell: |
        kubectl get nodes {{ inventory_hostname }}
      register: node_status
      delegate_to: "{{ groups['master'][0] }}"
      until: "'Ready' in node_status.stdout"
      retries: 10
      delay: 10
      when: inventory_hostname in groups['workers']
      tags:
        - join
    